{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pywhatkit      #for whatsapp\n",
    "import boto3          #for aws cli\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import smtplib\n",
    "import imghdr\n",
    "from email.message import EmailMessage\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Collecting Samples Complete\n"
     ]
    }
   ],
   "source": [
    "### Step 1 - Create Training Data\n",
    "\n",
    "# Load HAAR face classifier\n",
    "warnings. filterwarnings(action='ignore')\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load functions\n",
    "def face_extractor(img):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.5, 5)\n",
    "    \n",
    "    if faces ==():\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face\n",
    "\n",
    "# Initialize Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "# Collect 100 samples of your face from webcam input\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        count += 1\n",
    "        face = cv2.resize(face_extractor(frame), (400, 400))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Save file in specified directory with unique name\n",
    "        file_name_path = 'face/Dataset1/' + str(count) + '.jpg'\n",
    "        cv2.imwrite(file_name_path, face)\n",
    "\n",
    "        # Put count on images and display live count\n",
    "        cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow('Face Cropper', face)\n",
    "        \n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "\n",
    "    if cv2.waitKey(1) == 13 or count == 200: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      \n",
    "print(\"Collecting Samples Complete\")\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Collecting Samples Complete\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load HAAR face classifier\n",
    "warnings. filterwarnings(action='ignore')\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load functions\n",
    "def face_extractor(img):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.5, 5)\n",
    "    \n",
    "    if faces ==():\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face\n",
    "\n",
    "# Initialize Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "# Collect 100 samples of your face from webcam input\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        count += 1\n",
    "        face = cv2.resize(face_extractor(frame), (400, 400))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Save file in specified directory with unique name\n",
    "        file_name_path = './face/Dataset2/' + str(count) + '.jpg'\n",
    "        cv2.imwrite(file_name_path, face)\n",
    "\n",
    "        # Put count on images and display live count\n",
    "        cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow('Face Cropper', face)\n",
    "        \n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "#        pass\n",
    "\n",
    "    if cv2.waitKey(1) == 13 or count == 200: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      \n",
    "print(\"Collecting Samples Complete\")\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained sucessefully\n"
     ]
    }
   ],
   "source": [
    "# Get the training data we previously made\r\n",
    "import cv2\r\n",
    "import numpy as np\r\n",
    "from os import listdir\r\n",
    "from os.path import isfile, join\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "training_data = []\r\n",
    "labels = []\r\n",
    "\r\n",
    "#1\r\n",
    "data_path = './face/Dataset1/'\r\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\r\n",
    "\r\n",
    "for i, files in enumerate(onlyfiles):\r\n",
    "    img_path = data_path + onlyfiles[i]\r\n",
    "    images = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\r\n",
    "    training_data.append(np.asarray(images, dtype=np.uint8))\r\n",
    "    labels.append(1)\r\n",
    "#2\r\n",
    "data_path = './face/Dataset2/'\r\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\r\n",
    "\r\n",
    "for i, files in enumerate(onlyfiles):\r\n",
    "    img_path = data_path + onlyfiles[i]\r\n",
    "    images = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\r\n",
    "    training_data.append(np.asarray(images, dtype=np.uint8))\r\n",
    "    labels.append(2)\r\n",
    "    \r\n",
    "    \r\n",
    "\r\n",
    "    \r\n",
    "labels = np.asarray(labels, dtype=np.int32)\r\n",
    "\r\n",
    "model = cv2.face_LBPHFaceRecognizer.create()\r\n",
    "\r\n",
    "model.train(np.asarray(training_data), np.asarray(labels))\r\n",
    "\r\n",
    "model.write('model_save.yml')\r\n",
    "\r\n",
    "print(\"Model trained sucessefully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mail(img):\r\n",
    "    Sender_Email = \"deepaksingodiya2000@gmail.com\"\r\n",
    "    Reciever_Email = \"deepaksainisgi@gmail.com\"\r\n",
    "    Password=\"\"\r\n",
    "    h = open(\"pass.txt\", \"r\")\r\n",
    "    for line in h:\r\n",
    "        Password=line\r\n",
    "    h.close()\r\n",
    "    print(\"mail running\")\r\n",
    "    newMessage = EmailMessage()                         \r\n",
    "    newMessage['Subject'] = \"Face Successfullly detected\" \r\n",
    "    newMessage['From'] = Sender_Email                   \r\n",
    "    newMessage['To'] = Reciever_Email                   \r\n",
    "    newMessage.set_content('Image attached!')\r\n",
    "    \r\n",
    "    cv2.imwrite(\"face.jpg\",img)\r\n",
    "    with open('face.jpg', 'rb') as f:\r\n",
    "        image_data = f.read()\r\n",
    "        image_type = imghdr.what(f.name)\r\n",
    "        image_name = f.name\r\n",
    "        \r\n",
    "    newMessage.add_attachment(image_data, maintype='image', subtype=image_type, filename=image_name)\r\n",
    "    \r\n",
    "    with smtplib.SMTP_SSL('smtp.gmail.com', 465) as smtp:\r\n",
    "        smtp.login(Sender_Email, Password)              \r\n",
    "        smtp.send_message(newMessage)\r\n",
    "        print(\"logging in successfull\")\r\n",
    "        \r\n",
    "\r\n",
    "\r\n",
    "def whatsapp():\r\n",
    "    now = datetime.now()\r\n",
    "    H = int(now.strftime(\"%H\"))\r\n",
    "    M = int(now.strftime(\"%M\"))\r\n",
    "    pywhatkit.sendwhatmsg('+919990345500', 'HEY!! FACE DETECTED',H,M+1)\r\n",
    "    print(\"whatsaap success\")\r\n",
    "\r\n",
    "def aws():\r\n",
    "    subprocess.getoutput(\"terraform init\")\r\n",
    "    subprocess.getoutput('terraform apply --auto-approve')\r\n",
    "    print(\"AWS Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag1=0\r\n",
    "flag2=0\r\n",
    "warnings. filterwarnings(action='ignore')\r\n",
    "\r\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\r\n",
    "\r\n",
    "model = cv2.face_LBPHFaceRecognizer.create()\r\n",
    "model.read('model_save.yml')\r\n",
    "\r\n",
    "def face_detector(img, size=0.5):\r\n",
    "    \r\n",
    "    # Convert image to grayscale\r\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\r\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\r\n",
    "    if faces is ():\r\n",
    "        return img, []\r\n",
    "    \r\n",
    "    \r\n",
    "    for (x,y,w,h) in faces:\r\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),1)\r\n",
    "        roi = img[y:y+h, x:x+w]\r\n",
    "        roi = cv2.resize(roi, (200, 200))\r\n",
    "    return img, roi\r\n",
    "\r\n",
    "\r\n",
    "# Open Webcam\r\n",
    "cap = cv2.VideoCapture(0)\r\n",
    "while True:\r\n",
    "\r\n",
    "    ret, frame = cap.read()\r\n",
    "    \r\n",
    "    image, face = face_detector(frame)\r\n",
    "    \r\n",
    "    try:\r\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\r\n",
    "\r\n",
    "        # Pass face to prediction model\r\n",
    "        # \"results\" comprises of a tuple containing the label and the confidence value\r\n",
    "        results = model.predict(face)\r\n",
    "        \r\n",
    "        if results[1] < 500:\r\n",
    "            confidence = int( 100 * (1 - (results[1])/400) )\r\n",
    "            display_string = str(confidence) + '% Confident'\r\n",
    "            \r\n",
    "        \r\n",
    "        \r\n",
    "        if results[0]==1:\r\n",
    "            if (confidence > 80) and flag1==0:\r\n",
    "                \r\n",
    "                cv2.putText(image, \"Hello, Deepak\", (250, 450), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\r\n",
    "                cv2.putText(image, display_string, (0, 50), cv2.FONT_HERSHEY_SCRIPT_COMPLEX, 1, (255,255,250), 2)\r\n",
    "                cv2.imshow('Face Recognition', image )\r\n",
    "                if(cv2.waitKey(2)==13):\r\n",
    "                    mail(face)\r\n",
    "                    whatsapp()\r\n",
    "                    flag1=1\r\n",
    "                    \r\n",
    "                    \r\n",
    "                \r\n",
    "        elif(results[0]==2):\r\n",
    "            if (confidence > 80)and flag2==0:\r\n",
    "                cv2.putText(image, \"Hello, Rahul\", (250, 450), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\r\n",
    "                cv2.putText(image, display_string, (0, 50), cv2.FONT_HERSHEY_SCRIPT_COMPLEX, 1, (255,255,250), 2)\r\n",
    "                cv2.imshow('Face Recognition', image )\r\n",
    "                if(cv2.waitKey(2)==13):\r\n",
    "                    aws()\r\n",
    "                    flag2=1\r\n",
    "            \r\n",
    "\r\n",
    "         \r\n",
    "        else: \r\n",
    "            cv2.putText(image, \"Unknown Person\", (250, 450), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\r\n",
    "            cv2.imshow('Face Recognition', image )\r\n",
    "\r\n",
    "    except:\r\n",
    "        cv2.putText(image, \"NO FACE FOUND\", (220, 120) , cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\r\n",
    "        cv2.putText(image, \"Looking for Face\", (250, 450), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\r\n",
    "        cv2.imshow('Face Recognition', image )\r\n",
    "        \r\n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\r\n",
    "        break\r\n",
    "\r\n",
    "cap.release()\r\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "513dc2e41d739bb2c947903f3c0bbf636d03aa53ab50e61c694a27481c81805e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit (virtualenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}